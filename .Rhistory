getwd()
counts_raw <- read.delim(data/counts-raw.txt.gz)
counts_raw <- read.delim("data/counts-raw.txt.gz")
ls()
dim(counts_raw)
dim(counts_raw)
tail(counts_raw)
counts_raw[1, 10]
counts_raw[1:3, 10:12]
counts_raw[1:3, ]
counts_raw[1:10, "pmid"]
str(counts_raw)
str(counts_raw$daysSincePublished)
head(counts_raw$daysSincePublished / 7)
is.numeric(counts_raw$daysSincePublished)
str(counts_raw$journal)
levels(counts_raw$journal)
counts_raw$authorsCount == NA
counts_raw$authorsCount[1:10]
which(counts_raw$authorsCount==NA)
counts_raw$authorsCount==NA
anyNA(counts_raw$authorsCount[1:10])
is.na(counts_raw$authorsCount[1:10])
counts_raw$authorsCount==NA
counts_raw$authorsCount[1:10]==NA
which(counts_raw$authorsCount[1:10]==NA)
which(counts_raw$authorsCount)
which(counts_raw$authorsCount==6)
counts_raw$authorsCount[1:10]
which(counts_raw$authorsCount=="NA")
which(counts_raw$authorsCount=="NA")
which(counts_raw$authorsCount==NULL)
which(counts_raw$authorsCount==6)
summary(counts_raw$wosCountThru2011)
mean(counts_raw$wosCountThru2011)
hist(counts_raw$wosCountThru2011)
hist(sqrt(counts_raw$wosCountThru2011)
)
plot(counts_raw$daysSincePublished, counts_raw$wosCountThru2011)
counts_raw$authorsCount >7
counts_raw$authorsCount[1:10] > 7
which(counts_raw$authorsCount>7)
counts_raw$authorsCount[1:10] > 7
dim(counts_raw[counts_raw$journal == "pone",])
dim(counts_raw[counts_raw$journal %in% c("pone", "pbio", "pgen"),])
dim(counts_raw[grepl("Immunology", counts_raw$plosSubjectTags),])
ls
ls()
if (anyNA(counts_raw$authorsCount)) {
print("Be careful!")
} else{
print("You sexy.")
}
dim(cars)
dim(cars)
cars
The number of cars is `r dim(cars[1])`.
getwd()
counts_raw <- read.delim("data/counts-raw.txt.gz")
counts_norm < -read.delim("data/counts-norm.txt.gz")
hist(counts_raw$authorsCount, main= "Authors per paper", xlab="# authors", ylab="# papers")
library("rmarkdown")
render("Altmetrics analyses.Rmd")
hist(counts_raw$facebookLikeCount, main="FB Likes per paper", xlab="Likes", ylab="# papers", breaks = 50, xlim=range(0,50))
hist(counts_raw$facebookLikeCount, main="FB Likes per paper", xlab="Likes", ylab="# papers", breaks = 500, xlim=range(0,50))
which.max(counts_raw$facebookShareCount)
counts_raw[16201,]
counts_raw[16201,"title"]
for(i in 1:10){
print(i)
}
for(i in 1:10){
print(i%5)
}
for(i in 1:10){
print(i/5)
}
for(i in c("cat", "dog", "mouse")){
print(i)
}
for(i in c("cat", "dog", "mouse")){
print(i)+"dies"
}
for(i in c("cat", "dog", "mouse")){
cat(i+"dies")
}
for(i in c("cat", "dog", "mouse")){
cat(i, " dies")
}
for(i in c("cat", "dog", "mouse")){
cat(i, " dies /n")
}
for(i in c("cat", "dog", "mouse")){
cat(i, " dies \n")
}
for(i in 1:length(counts_raw$wosCountThru2011)){
x <- c(x, counts_raw$wosCountThru2011 +1)
}
for(i in c("cat", "dog", "mouse")){
cat(i, " dies \n")
}
x <- numeric()
for(i in 1:length(counts_raw$wosCountThru2011)){
x <- c(x, counts_raw$wosCountThru2011 +1)
}
head(x)
mean(x)
dim(x)
typeof(x)
x <- numeric(length=length(counts_raw$wosCountThru2011))
x <- numeric(length=length(counts_raw$wosCountThru2011))
for(i in 1:length(counts_raw$wosCountThru2011)){
#x <- c(x, counts_raw$wosCountThru2011 +1) #Adding things on to a vector is slow.
x[i] <- counts_raw$wosCountThru2011+1 #It's faster to index into the list. Significantly.
}
warnings()
x <- numeric(length=length(counts_raw$wosCountThru2011))
for(i in 1:length(counts_raw$wosCountThru2011)){
#x <- c(x, counts_raw$wosCountThru2011 +1) #Adding things on to a vector is slow.
x[i] <- counts_raw$wosCountThru2011[i]+1 #It's faster to index into the list. Significantly.
}
levels(counts_raw)
levels(counts_raw$journal)
results <- numeric(length=length(levels(counts_raw$journal)))
names(results) <-levels(counts_raw$journal)
results
results["pone"]
names(results) <-levels(counts_raw$journal)
for(journal in levels(counts_raw$journal)){
results[journal] <- mean(counts_raw$wosCountThru2011[counts_raw$journal == journal])
}
results
head(counts_raw$wosCountThru2011)
counts_raw$wosCountThru2011
research <- filter(counts_raw, articleType == "Research Article")
research <- filter(counts_raw, articletype == "Research Article")
research_2006 <- filter(research, year == 2006)
library("dplyr")
research <- filter(counts_raw, articleType == "Research Article")
research_2006 <- filter(research, year == 2006)
nrow(research_2006)
research_2006_fb_tweet_disease <- filter(research, year==2006, facebookCommentCount >0 | backtweetsCount >0, grepl("Infectious Diseases"))
research_2006_fb_tweet_disease <- filter(research, year==2006, facebookCommentCount >0 | backtweetsCount >0, grepl("Infectious Diseases"))
research_2006_fb_tweet_disease <- filter(research, year==2006, facebookCommentCount >0 | backtweetsCount >0, grepl("Infectious Diseases", plosSubjectTags))
nrow(research_2006_fb_tweet_disease)
article_info <- select(research:doiauthorsCount)
article_info <- select(research:doi_authorsCount)
article_info <- select(research, doi:authorsCount)
colnames(article_info)
metrics <- select(research, contains("Count"))
colnames(metrics)
metrics <- select(research, contains("Count"), -authorsCount)
colnames(metrics)
metrics <- select(research, contains("Count"), -authorsCount, f1000Factor, wikipediaCites)
colnames(metrics)
head(select(research, journal))
head(select(research, 3))
research
slice(article_info, 1:3)
low_cite <- filter(research, cite <= 2008, pdfDownloadsCount > 1000, mendeleyReadersCount > 15, wosCountThru2011 < 10)
low_cite <- filter(research, cite <= 2008, pdfDownloadsCount > 1000, mendeleyReadersCount > 15)#, wosCountThru2011 < 10)
low_cite <- filter(research, cite <= 2008, pdfDownloadsCount > 1000#), mendeleyReadersCount > 15)#, wosCountThru2011 < 10)
)
low_cite <- filter(research, year <= 2008, pdfDownloadsCount > 1000, mendeleyReadersCount > 15, wosCountThru2011 < 10)
low_cite <- select(filter(research, year <= 2008, pdfDownloadsCount > 1000, mendeleyReadersCount > 15, wosCountThru2011 < 10), journal, title, year)
low_cite
low_cite
facebook_2006 <- research %>%
filter(year==2006)
%>% select(contains("facebook"))
head(facebook_2006)
facebook_2006 <- research %>% filter(year==2006) %>% select(contains("facebook"))
head(facebook_2006)
research %>% filter(year==2006) %>% select(contains("facebook")) %>% head
research %>% arrange(authorsCount, wosCountThru2011) %>% select(authorsCount, wosCountThru2011)
research %>%
arrange(authorsCount, wosCountThru2011) %>%
select(authorsCount, wosCountThru2011) %>%
slice(1:10)
research %>%
arrange(desc(authorsCount), desc(wosCountThru2011)) %>%
select(authorsCount, wosCountThru2011) %>%
slice(1:10)
research %>% arrange(desc(wosCountThru2011))
research %>% arrange(desc(wosCountThru2011)) %>% select(title) %>% slice(1:3)
research %>% arrange(desc(authorsCount)) %>% select(authorsCount, title, journal, plosSubjectTags) %>% slice(1:3)
research %>% arrange(desc(wosCountThru2011)) %>% select(title) %>% slice(1:3)
research %>% arrange(desc(wosCountThru2011)) %>% select(title) %>% subset(1:3)
research %>% arrange(desc(wosCountThru2011)) %>% select(title) %>% choose(1:3)
research %>% arrange(desc(wosCountThru2011)) %>% select(title) %>% (1:3)
research %>% arrange(desc(wosCountThru2011)) %>% select(title) %>% slice(1:3)
research %>% arrange(desc(wosCountThru2011)) %>% select(title) %>% [1:3,]#slice(1:3)
research %>% arrange(desc(wosCountThru2011)) %>% select(title) %>% [,1:3]#slice(1:3)
research %>% arrange(desc(wosCountThru2011)) %>% select(title)[1:3,] #%>% slice(1:3)
research %>% arrange(desc(wosCountThru2011)) %>% select(title)[1:3,] #%>% slice(1:3)
research %>% arrange(desc(wosCountThru2011)) %>% select(title)#[1:3,] #%>% slice(1:3)
research %>% arrange(desc(wosCountThru2011)) %>% select(title)[1:3,] #%>% slice(1:3)
research %>% arrange(desc(wosCountThru2011)) %>% (select(title))[1:3,] #%>% slice(1:3)
research %>% arrange(desc(authorsCount)) %>% select(authorsCount, title, journal, plosSubjectTags) %>% slice(1:3)
research <- research %>% mutate(weeksSincePublished = daysSincePublished / 7, yearsSincePublished=weeksSincePublished /52)
research %>% select(contains("Since")) %>% slice(1:10)
research %>% summarize(plos_mean = mean(plosCommentCount))
summarize(research, plos_mean = mean(plosCommentCount), plos_sd = sd(plosCommentCount))
summarize(research, plos_mean = mean(plosCommentCount), plos_sd = sd(plosCommentCount), num =n())
research %>% group_by(journal) %>% summarize(tweets_mean = mean(backtweetsCount))
research %>% group_by(journal, year) %>% summarize(tweets_mean = mean(backtweetsCount))
tweets_per_journal <- research %>% group_by(journal) %>% summarize(total_articles = n(), tweets_mean=mean(backtweetsCount), SEM = sd(backtweetsCount)/sqrt(total_articles))
tweets_per_journal
class(tweets_per_journal)
y = wosCountThru2011))
p <- ggplot(data = research, mapping = aes(x = pdfDownloadsCount, y = wosCountThru2011))
library("ggplot2")
p <- ggplot(data = research, mapping = aes(x = pdfDownloadsCount, y = wosCountThru2011))
p + geom_point()
p <- ggplot(research, aes(x = pdfDownloadsCount, y = wosCountThru2011)) + geom_point()
p
p <- ggplot(research, aes(x = pdfDownloadsCount, y = wosCountThru2011)) + geom_point(aes(color=journal))
p
?ggplot
p <- ggplot(research, aes(x = pdfDownloadsCount, y = wosCountThru2011)) + geom_point(aes(color=journal, size=authorsCount, alpha=daysSincePublished))
p
p <- ggplot(research, aes(x = pdfDownloadsCount, y = wosCountThru2011)) + geom_point(aes(color=journal, size=authorsCount, alpha=daysSincePublished)) + geom_smooth()
p
p <- ggplot(research, aes(x = pdfDownloadsCount, y = wosCountThru2011, color=journal)) + geom_point(aes(size=authorsCount, alpha=daysSincePublished)) + geom_smooth()
p
p <- ggplot(research, aes(x = daysSincePublished, y = wosCountThru2011, color=journal)) + geom_point(aes(color=journal, alpha=0.5)) + geom_smooth(color="red")
p
p <- ggplot(research, aes(x = daysSincePublished, y = wosCountThru2011)) + geom_point(aes(color=journal, alpha=0.5)) + geom_smooth(color="red")
p <- ggplot(research, aes(x = daysSincePublished, y = wosCountThru2011)) + geom_point(aes(color=journal), alpha=0.5)) + geom_smooth(color="red")
p
p <- ggplot(research, aes(x = daysSincePublished, y = wosCountThru2011)) + geom_point(aes(color=journal), alpha=0.5) + geom_smooth(color="red")
p
p <- ggplot(research, aes(x=pdfDownloadsCount, y=wosCountThru2011)) + geom_point(aes(color=journal)) + geom_smoot()
p
p <- ggplot(research, aes(x=pdfDownloadsCount, y=wosCountThru2011)) + geom_point(aes(color=journal)) + geom_smooth()
p
p + scale_x_log10() + scale_y_log10()
p + (scale_x_log10()+1) + (scale_y_log10()+1)
p <- ggplot(research, aes(x=log10(pdfDownloadsCount)+1, y=log10(wosCountThru2011)+1)) + geom_point(aes(color=journal)) + geom_smooth()
p
p <- ggplot(research, aes(x=log10(pdfDownloadsCount+1), y=log10(wosCountThru2011+1))) + geom_point(aes(color=journal)) + geom_smooth()
p
p <- ggplot(research, aes(x=log10(pdfDownloadsCount+1), y=log10(wosCountThru2011+1))) + geom_point(aes(color=journal)) + geom_smooth() + scale_x_continous(breaks=c(1,3), labels=c(10, 1000))
p
p <- ggplot(research, aes(x=log10(pdfDownloadsCount+1), y=log10(wosCountThru2011+1))) + geom_point(aes(color=journal)) + geom_smooth() + scale_x_continuous(breaks=c(1,3), labels=c(10, 1000))
p
p <- ggplot(research, aes(x=log10(pdfDownloadsCount+1), y=log10(wosCountThru2011+1))) + geom_point(aes(color=journal)) + geom_smooth() + scale_x_continuous(breaks=c(1,3), labels=c(10, 1000)) + scale_y_continuous(breaks=c(1,3), labels=c(10, 1000))
p
p <- ggplot(research, aes(x=log10(pdfDownloadsCount+1), y=log10(wosCountThru2011+1))) + geom_point(aes(color=journal)) + geom_smooth() + scale_x_continuous(breaks=c(1,3), labels=c(10, 1000)) + scale_y_continuous(breaks=c(1,3), labels=c(10, 1000), limits = c(1,3))
p
p + scale_color_grey()
p + scale_color_manual(values = c("red", "green", "blue", "orange", "pink", "yellow", "purple"))
library("RcolorBrewer")
library("RColorBrewer")
display.brewer.all(type="qual")
p + scale_color_brewer(palette= dark2)
p + scale_color_brewer(palette= "Dark2")
p + scale_color_brewer(palette= "Dark2", labels=1:7, name="PLOS")
p <- ggplot(research, aes(x = sqrt(pdfDownloadsCount), y = sqrt(wosCountThru2011))) + scale_color_brewer(palette="Accent") geom_point() + geom_smooth()
p <- ggplot(research, aes(x = sqrt(pdfDownloadsCount), y = sqrt(wosCountThru2011))) + scale_color_brewer(palette="Accent") + geom_point() + geom_smooth()
p
p <- ggplot(research, aes(x = sqrt(pdfDownloadsCount), y = sqrt(wosCountThru2011))) + scale_color_brewer(palette="Accent")# + geom_point() + geom_smooth()
p
p <- ggplot(research, aes(x = sqrt(pdfDownloadsCount), y = sqrt(wosCountThru2011))) + geom_point() + scale_color_brewer(palette="Accent")# + geom_point() + geom_smooth()
p
p + scale_color_brewer(palette="Accent")
p <- ggplot(research, aes(x=log10(pdfDownloadsCount+1), y=log10(wosCountThru2011+1))) + geom_point(aes(color=journal)) + geom_smooth() + scale_x_continuous(breaks=c(1,3), labels=c(10, 1000)) + scale_y_continuous(breaks=c(1,3), labels=c(10, 1000), limits = c(1,3))
p <- ggplot(research, aes(x = sqrt(pdfDownloadsCount), y = sqrt(wosCountThru2011))) + geom_point() + scale_color_brewer(palette="Accent")
p
p <- ggplot(research, aes(x = sqrt(pdfDownloadsCount), y = sqrt(wosCountThru2011))) + geom_point(aes(color=journal)) + geom_smooth() + scale_color_brewer(palette="Accent")
p
p + facet_wrape(~journal)
p + facet_wrap(~journal)
p + facet_wrap(~journal, ncol=2)
p + facet_grid(journal~immuno)
research <- mutate(research, immuno=grepl("Immunology", plosSubjectTags))
p <- ggplot(research, aes(x = sqrt(pdfDownloadsCount), y = sqrt(wosCountThru2011))) + geom_point(aes(color=journal)) + geom_smooth() + scale_color_brewer(palette="Accent")
p + facet_grid(journal~immuno)
p <- ggplot(research, aes(x=journal, y=sqrt(wosCountThru2011))) + geom_boxplot()
p
tweets_per_journal <- research %>% group_by(journal) %>% summarize(total_articles = n(), tweets_mean=mean(backtweetsCount), SEM = sd(backtweetsCount)/sqrt(total_articles))
tweets_bar <- ggplot(tweets_per_journal, aes(x=journal, y=mean)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin = mean-sem, ymax=mean +sem))
tweets_bar
tweets_bar <- ggplot(tweets_per_journal, aes(x=journal, y=mean)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin = (mean-sem), ymax=(mean +sem)))
tweets_bar
tweets_per_journal <- research %>% group_by(journal) %>% summarize(total_articles = n(), tweets_mean=mean(backtweetsCount), SEM = sd(backtweetsCount)/sqrt(total_articles))
tweets_per_journal
tweets_bar <- ggplot(tweets_per_journal, aes(x=journal, y=mean)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin = (mean-sem), ymax=(mean +sem)))
tweets_bar
geom_bar(stat = "identity")
tweets_bar
tweets_per_journal
tweets_per_journal <- research %>%
group_by(journal) %>%
summarize(num = n(),
mean = mean(backtweetsCount),
sem = sd(backtweetsCount) / sqrt(num))
tweets_per_journal
tweets_bar <- ggplot(tweets_per_journal, aes(x=journal, y=mean)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin = (mean-sem), ymax=(mean +sem)))
tweets_bar
tweets_bar <- ggplot(tweets_per_journal, aes(x=journal, y=mean)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin = (mean-SEM), ymax=(mean +SEM)))
tweets_bar
sem
tweets_bar
tweets_bar <- ggplot(tweets_per_journal, aes(x=journal, y=mean)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin = (mean-sem), ymax=(mean +sem)))
tweets_per_journal
tweets_bar
tweets_bar <- ggplot(tweets_per_journal, aes(x=journal, y=mean)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin = (mean-sem), ymax=(mean +sem), width=0.1)) + geom_text(aes(label=num), hjust=0, vjust=0)
tweets_bar
tweets_per_journal <- research %>% group_by(journal) %>% summarize(total_articles = n(), tweets_mean=mean(backtweetsCount), SEM = sd(backtweetsCount)/sqrt(total_articles))
tweets_per_journal
tweets_bar <- ggplot(tweets_per_journal, aes(x=journal, y=mean)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin = (mean-SEM), ymax=(mean +SEM)))
tweets_bar
head(tweets_per_journal)
tweets_per_journal <- research %>% group_by(journal) %>% summarize(total_articles = n(), tweets_mean=mean(backtweetsCount), SEM = sd(backtweetsCount)/sqrt(total_articles))
tweets_per_journal1 <- research %>% group_by(journal) %>% summarize(total_articles = n(), tweets_mean=mean(backtweetsCount), SEM = sd(backtweetsCount)/sqrt(total_articles))
tweets_per_journal2 <- research %>%
group_by(journal) %>%
summarize(num = n(),
mean = mean(backtweetsCount),
sem = sd(backtweetsCount) / sqrt(num))
tweets_per_journal1
tweets_per_journal2
tweets_bar <- ggplot(tweets_per_journal1, aes(x=journal, y=tweets_mean)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin = (mean-SEM), ymax=(mean +SEM), width=0.1)) + geom_text(aes(label=num), hjust=0, vjust=0)
tweets_bar
tweets_bar <- ggplot(tweets_per_journal1, aes(x=journal, y=tweets_mean)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin = (tweets_mean-SEM), ymax=(tweets_mean +SEM), width=0.1)) + geom_text(aes(label=num), hjust=0, vjust=0)
tweets_bar
tweets_bar <- ggplot(tweets_per_journal1, aes(x=journal, y=tweets_mean)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin = (tweets_mean-SEM), ymax=(tweets_mean +SEM), width=0.1)) + geom_text(aes(label=total_articles), hjust=0, vjust=0)
tweets_bar
tweets_per_journal_per_year <- research %>% group_by(journal, year) %>% summarize(total_articles = n(), tweets_mean=mean(backtweetsCount), SEM = sd(backtweetsCount)/sqrt(total_articles))
tweets_bar + facet_wrap(~year)
tweets_per_journal_per_year
tweets_pjpy <- ggplot(tweets_per_journal_per_year, aes(x=journal, y=tweets_mean)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin = (tweets_mean-SEM), ymax=(tweets_mean +SEM), width=0.1))
tweets_pjpy + facet_wrap(~year)
tweets_pjpy <- ggplot(tweets_per_journal_per_year, aes(x=journal, y=tweets_mean)) + geom_point() + geom_errorbar(aes(ymin = (tweets_mean-SEM), ymax=(tweets_mean +SEM), width=0.1))
tweets_pjpy + facet_wrap(~year)
tweets_bar + labs(title= "Mean tweets per journal per year", x="Journal", y"Mean # tweets")
tweets_bar + labs(title= "Mean tweets per journal per year", x="Journal", y="Mean # tweets")
tweets_pjpy + labs(title= "Mean tweets per journal per year", x="Journal", y="Mean # tweets")
tweets_pjpy <- ggplot(tweets_per_journal_per_year, aes(x=journal, y=tweets_mean)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin = (tweets_mean-SEM), ymax=(tweets_mean +SEM), width=0.1))
tweets_pjpy + facet_wrap(~year)
tweets_pjpy + labs(title= "Mean tweets per journal per year", x="Journal", y="Mean # tweets")
tweets_pjpy <- ggplot(tweets_per_journal_per_year, aes(x=journal, y=tweets_mean)) + geom_bar(stat="identity") + geom_errorbar(aes(ymin = (tweets_mean-SEM), ymax=(tweets_mean +SEM), width=0.1))
tweets_pjpy + facet_wrap(~year)
tweets_full <- tweets_pjpy + facet_wrap(~year)
tweets_full + labs(title= "Mean tweets per journal per year", x="Journal", y="Mean # tweets")
tweets_full + theme_bw()
tweets_full + theme_classic()
tweets_full + theme_minimal()
